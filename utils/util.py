import stat
import os
import zipfile
import logging
import traceback
import boto3
import requests
import logging

from concurrent.futures import ThreadPoolExecutor
from typing import Any, Callable, Generator, Iterable, Literal, Protocol, Optional, Dict
from queue import Queue
from threading import Thread, Lock, Event
from time import sleep
from keyword import kwlist
from zipfile import ZipFile
from lib.console import ProgressBar, notice
import subprocess
from os import path
from pathlib import Path
from botocore.config import Config

class TemplateString:
    """
    Template string generator.

    :Example:
    .. code-block:: python
        CONSTANT = TemplateString("What%s a %s %s.")
        CONSTANT("", "fast", "fox")
        "What a fast fox."
    """

    def __init__(self, template: str) -> None:
        self.template = template

    def __call__(self, *args: Any) -> str:
        return self.template % args
class Utils:
    @staticmethod
    def convert_name_to_available(variable_name: str) -> str:
        """Convert varaible name to suitable with python.

        Args:
            variable_name (str): Name.

        Returns:
            str: Available string in python.
        """
        if not variable_name:
            return "_"
        if variable_name[0].isdigit():
            variable_name = "_" + variable_name
        if variable_name in kwlist:
            variable_name = f"{variable_name}_"
        return variable_name
        
class TaskManagerWorkerProtocol(Protocol):
    def __call__(
        self, task_manager: "TaskManager", *args: Any, **kwargs: Any
    ) -> None: ...


class TaskManager:
    def __init__(
        self,
        target_workers: int,
        max_workers: int,
        worker: TaskManagerWorkerProtocol,
        tasks: Queue[Any] = Queue(),
    ) -> None:
        """A simplified thread pool manager.

        Args:
            max_workers (int): Maximum number of threads to use.
            worker (Callable[..., None]): The worker function executed by each thread.
        """
        self.target_workers = target_workers
        self.max_workers = max_workers
        self.worker = worker
        self.tasks = tasks
        self.stop_task = False
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        self.futures: list[concurrent.futures.Future] = []
        self.lock = Lock()
        self.event = Event()
        self.__cancel_callback: tuple[Callable, tuple] | None = None
        self.__pool_condition: Callable = lambda: self.tasks.empty() or self.stop_task
        self.__force_exit = False

    def __enter__(self) -> "TaskManager":
        """Start the worker pool."""
        return self

    def __exit__(self, exc_type, exc_val, exc_tb) -> None:
        """Shutdown the worker pool."""
        is_force = self.stop_task or self.__force_exit
        self.executor.shutdown(wait=not is_force, cancel_futures=is_force)

    def __set_conditions(self, func: Callable | None = None) -> None:
        if not func:
            self.__pool_condition = lambda: self.tasks.empty() or self.stop_task
        else:
            self.__pool_condition = func

    def add_worker(self, *args: Any) -> None:
        """Add a task to the worker queue."""
        future = self.executor.submit(self.worker, *args)
        self.futures.append(future)

    def increase_worker(self, num: int = 1) -> None:
        """Increase worker with exsist worker parameters."""
        self.target_workers += num

    def set_cancel_callback(self, callback: Callable[..., None], *args) -> None:
        """Set a callback for task canceled."""
        self.__cancel_callback = (callback, args)

    def set_force_shutdown(self, force: bool = True) -> None:
        """Set is or not shutdown without wait."""
        self.__force_exit = force

    def set_relate(
        self, mode: Literal["event"], related_manager: "TaskManager"
    ) -> None:
        """Set a relation to another task by a flag."""
        if mode == "event":
            self.event = related_manager.event
            self.__set_conditions(
                lambda: self.stop_task or (self.tasks.empty() and self.event.is_set())
            )

    def import_tasks(self, tasks: Iterable[Any]) -> None:
        """Import tasks from iterable sequency and set to instance task

        Args:
            tasks (Iterable[Any]): Any iterable elements.
        """
        queue_tasks: Queue[Any] = Queue()
        for task in tasks:
            queue_tasks.put(task)
        self.tasks = queue_tasks

    def run_without_block(self, *worker_args: Any) -> Thread:
        """Same as run and without block."""
        thread = Thread(target=self.run, args=worker_args, daemon=True)
        thread.start()
        return thread

    def run(self, *worker_args: Any) -> None:
        """Start worker and give parameters to worker."""
        try:
            while not self.__pool_condition():
                while len(self.futures) < self.target_workers:
                    self.add_worker(*worker_args)
                self.futures = [f for f in self.futures if not f.done()]
                sleep(0.1)

        except KeyboardInterrupt:
            if self.__cancel_callback:
                self.__cancel_callback[0](*self.__cancel_callback[1])
            self.stop_task = True
            while not self.tasks.empty():
                self.tasks.get()
                self.tasks.task_done()
            self.executor.shutdown(wait=False, cancel_futures=True)
        finally:
            self.event.set()
            if not self.__force_exit:
                for future in self.futures:
                    future.result()

    def done(self) -> None:
        """Finish thread pool manually."""
        self.__exit__(None, None, None)

class ZipUtils:
    @staticmethod
    def extract_zip(
        zip_path: str | list[str],
        dest_dir: str,
        *,
        keywords: list[str] | None = None,
        zips_dir: str = "",
        password: bytes = bytes(),
        progress_bar: bool = True,
    ) -> list[str]:
        """Extracts specific files from a zip archive(s) to a destination directory.

        Args:
            zip_path (str | list[str]): Path(s) to the zip file(s).
            dest_dir (str): Directory where files will be extracted.
            keywords (list[str], optional): List of keywords to filter files for extraction. Defaults to None.
            zips_dir (str, optional): Base directory for relative paths when zip_path is a list. Defaults to "".
            progress_bar (str, optional): Create a progress bar during extract. Defaults to False.


        Returns:
            list[str]: List of extracted file paths.
        """
        if progress_bar:
            print(f"Extracting files from {zip_path} to {dest_dir}...")
        extract_list: list[str] = []
        zip_files = []

        if isinstance(zip_path, str):
            zip_files = [zip_path]
        elif isinstance(zip_path, list):
            zip_files = [os.path.join(zips_dir, p) for p in zip_path]

        os.makedirs(dest_dir, exist_ok=True)

        if progress_bar:
            bar = ProgressBar(len(extract_list), "Extract...", "items")
        for zip_file in zip_files:
            try:
                with ZipFile(zip_file, "r") as z:
                    z.setpassword(password)
                    if keywords:
                        extract_list = [
                            item for k in keywords for item in z.namelist() if k in item
                        ]
                        for item in extract_list:
                            try:
                                z.extract(item, dest_dir)
                            except Exception as e:
                                notice(str(e))
                            if progress_bar:
                                bar.increase()
                    else:
                        z.extractall(dest_dir)

            except Exception as e:
                notice(f"Error processing file '{zip_file}': {e}")
        if progress_bar:
            bar.stop()
        return extract_list

    @staticmethod
    def create_zip(
        source_dir: str,
        output_path: str,
        *,
        include_base_dir: bool = False,
        compression_level: int = zipfile.ZIP_DEFLATED,
        password: bytes = bytes(),
        progress_bar: bool = True
    ) -> bool:
        """Creates a zip file from a directory.

        Args:
            source_dir (str): Source directory to compress.
            output_path (str): Output zip file path.
            include_base_dir (bool, optional): Include the base directory in the zip. Defaults to False.
            compression_level (int, optional): Compression level. Defaults to zipfile.ZIP_DEFLATED.
            password (bytes, optional): Password for encryption. Defaults to empty bytes.
            progress_bar (bool, optional): Show progress bar. Defaults to True.

        Returns:
            bool: True if successful, False otherwise.
        """
        try:
            source_path = Path(source_dir)
            if not source_path.exists() or not source_path.is_dir():
                print(f"Source directory does not exist: {source_dir}")
                return False

            output_path_obj = Path(output_path)
            output_path_obj.parent.mkdir(parents=True, exist_ok=True)

            if progress_bar:
                print(f"Creating zip file: {output_path}")

            with zipfile.ZipFile(output_path, 'w', compression_level) as zipf:
                if password:
                    zipf.setpassword(password)
                
                files_to_compress = list(source_path.rglob('*'))
                
                if progress_bar:
                    total_files = len([f for f in files_to_compress if f.is_file()])
                    print(f"Compressing {total_files} files...")

                file_count = 0
                for file_path in files_to_compress:
                    if file_path.is_file():
                        if include_base_dir:
                            arcname = file_path.relative_to(source_path.parent)
                        else:
                            arcname = file_path.relative_to(source_path)
                        
                        if password:
                            zipf.write(file_path, arcname)
                        else:
                            zipf.write(file_path, arcname)
                        
                        file_count += 1
                        if progress_bar and file_count % 100 == 0:
                            print(f"Progress: {file_count}/{total_files} files compressed")

            if password and not ZipUtils.is_zip_encrypted(output_path):
                print("Warning: Password may not have been applied correctly.")

            if progress_bar:
                print(f"Zip file created successfully: {output_path}")
            return True

        except Exception as e:
            print(f"Error creating zip file: {e}")
            return False

    @staticmethod
    def is_zip_encrypted(zip_path: str) -> bool:
        """Check if a zip file is encrypted.

        Args:
            zip_path (str): Path to the zip file.

        Returns:
            bool: True if encrypted, False otherwise.
        """
        try:
            with zipfile.ZipFile(zip_path, 'r') as zipf:
                for info in zipf.infolist():
                    if info.flag_bits & 0x1:
                        return True
            return False
        except:
            return False

    # Used to parse the area where the EOCD (End of Central Directory) of the compressed file's central directory is located.
    @staticmethod
    def parse_eocd_area(data: bytes) -> tuple[int, int]:
        eocd_signature = b"\x50\x4b\x05\x06"
        eocd_offset = data.rfind(eocd_signature)
        if eocd_offset == -1:
            raise EOFError("Cannot read the eocd of file.")
        eocd = data[eocd_offset : eocd_offset + 22]
        _, _, _, _, _, cd_size, cd_offset, _ = struct.unpack("<IHHHHIIH", eocd)
        return cd_offset, cd_size

    # Used to parse the files contained in the central directory. Use for common apk.
    @staticmethod
    def parse_central_directory_data(data: bytes) -> list:
        file_headers = []
        offset = 0
        while offset < len(data):
            if data[offset : offset + 4] != b"\x50\x4b\x01\x02":
                raise BufferError("Cannot parse the central directory of file.")
            pack = struct.unpack("<IHHHHHHIIIHHHHHII", data[offset : offset + 46])

            uncomp_size = pack[9]
            file_name_length = pack[10]
            extra_field_length = pack[11]
            file_comment_length = pack[12]
            local_header_offset = pack[16]
            file_name = data[offset + 46 : offset + 46 + file_name_length].decode(
                "utf8"
            )

            file_headers.append(
                {"path": file_name, "offset": local_header_offset, "size": uncomp_size}
            )
            offset += 46 + file_name_length + extra_field_length + file_comment_length

        return file_headers

    @staticmethod
    def download_and_decompress_file(
        apk_url: str, target_path: str, header_part: bytes, start_offset: int
    ) -> bool:
        """Request partial data from an online compressed file and then decompress it."""
        try:
            header = struct.unpack("<IHHHHHIIIHH", header_part[:30])
            _, _, _, compression, _, _, _, comp_size, _, file_name_len, extra_len = (
                header
            )
            data_start = start_offset + 30 + file_name_len + extra_len
            data_end = data_start + comp_size
            compressed_data = FileDownloader(
                apk_url,
                headers={"Range": f"bytes={data_start}-{data_end - 1}"},
            )
            return ZipUtils.decompress_file_part(
                compressed_data, target_path, compression
            )
        except:
            return False

    @staticmethod
    def decompress_file_part(compressed_data_part, file_path, compress_method) -> bool:
        """Decompress pure compressed data. Return True if saved to path."""
        try:
            if compress_method == 8:  # Deflate compression
                decompressor = zlib.decompressobj(-zlib.MAX_WBITS)
                decompressed_data = decompressor.decompress(compressed_data_part)
                decompressed_data += decompressor.flush()
            else:
                decompressed_data = compressed_data_part
            with open(file_path, "wb") as file:
                file.write(decompressed_data)
            return True
        except:
            return False

class FileUtils:
    @staticmethod
    def find_files(
        directory: str,
        keywords: list[str],
        absolute_match: bool = False,
        sequential_match: bool = False,
    ) -> list[str]:
        """Retrieve files from a given directory based on specified keywords of file name.

        Args:
            directory (str): The directory to search for files.
            keywords (list[str]): A list of keywords to match file names.
            absolute_match (bool, optional): If True, matches file names exactly with the keywords. If False, performs a partial match (i.e., checks if any keyword is a substring of the file name). Defaults to False.
            sequential_match (bool, optional): If True, the final list will be matched sequentially based on the order of the provided keywords. If a keyword has multiple values, only one will be retained. A keyword that no result to be retrieved will correspond to a None value. Defaults to False.
        Returns:
            list[str]: A list of file paths that match the specified criteria.
        """
        paths = []
        for dir_path, _, files in os.walk(directory):
            for file in files:
                if absolute_match and file in keywords:
                    paths.append(os.path.join(dir_path, file))
                elif not absolute_match and any(
                    keyword in file for keyword in keywords
                ):
                    paths.append(os.path.join(dir_path, file))

        if not sequential_match:
            return paths

        sorted_paths = []
        # Sequential match part.
        for key in keywords:
            for p in paths:
                if key in p:
                    sorted_paths.append(p)
                    break

        return sorted_paths

class CommandUtils:
    @staticmethod
    def run_command(
        *commands: str,
        cwd: str | None = None,
    ) -> tuple[bool, str]:
        """
        Executes a shell command and returns whether it succeeded.

        Args:
            *commands (str): Command and its arguments as separate strings.

        Returns:
            tuple (bool, str): True if the command succeeded, False otherwise. And error string.
        """
        try:
            subprocess.run(
                list(commands),
                check=True,
                text=True,
                cwd=cwd,
                encoding="utf8",
            )
            return True, ""
        except Exception as e:
            return False, e

class CloudflareStorageManager:
    def __init__(
        self,
        account_id: str,
        api_token: str,
        r2_access_key_id: Optional[str] = None,
        r2_secret_access_key: Optional[str] = None
    ):
        self.account_id = account_id
        self.api_token = api_token
        self.r2_access_key_id = r2_access_key_id
        self.r2_secret_access_key = r2_secret_access_key
        self.logger = logging.getLogger("CloudflareStorage")
        
        if not self.logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
            self.logger.setLevel(logging.INFO)

    def get_r2_client(self, bucket_name: str):
        endpoint_url = f"https://{self.account_id}.r2.cloudflarestorage.com"
        return boto3.client(
            service_name="s3",
            endpoint_url=endpoint_url,
            aws_access_key_id=self.r2_access_key_id,
            aws_secret_access_key=self.r2_secret_access_key,
            region_name="auto",
            config=Config(signature_version="s3v4")
        )

class R2Transfer(CloudflareStorageManager):
    def upload_file(self, bucket_name: str, local_path: str, remote_key: str) -> Dict[str, Any]:
        result = {"success": False, "error": None}
        try:
            client = self.get_r2_client(bucket_name)
            local_file = Path(local_path)
            client.upload_file(str(local_file), bucket_name, remote_key)
            result.update({"success": True, "key": remote_key, "size": local_file.stat().st_size})
            self.logger.info(f"R2 Upload Success: {remote_key}")
        except Exception as e:
            result["error"] = str(e)
            self.logger.error(f"R2 Upload Failed: {e}")
        return result

    def download_file(self, bucket_name: str, remote_key: str, local_path: str) -> Dict[str, Any]:
        result = {"success": False, "error": None}
        try:
            client = self.get_r2_client(bucket_name)
            client.download_file(bucket_name, remote_key, local_path)
            result.update({"success": True, "path": local_path})
            self.logger.info(f"R2 Download Success: {remote_key}")
        except Exception as e:
            result["error"] = str(e)
        return result

class KVTransfer(CloudflareStorageManager):
    def put_value(self, namespace_id: str, key: str, value: str, expiration_ttl: int = None) -> Dict[str, Any]:
        url = f"https://api.cloudflare.com/client/v4/accounts/{self.account_id}/storage/kv/namespaces/{namespace_id}/values/{key}"
        headers = {"Authorization": f"Bearer {self.api_token}"}
        params = {"expiration_ttl": expiration_ttl} if expiration_ttl else {}
        
        try:
            response = requests.put(url, data=value, headers=headers, params=params)
            res_json = response.json()
            if res_json.get("success"):
                return {"success": True, "key": key}
            raise Exception(res_json.get("errors"))
        except Exception as e:
            self.logger.error(f"KV Put Failed: {e}")
            return {"success": False, "error": str(e)}

    def get_value(self, namespace_id: str, key: str) -> Dict[str, Any]:
        url = f"https://api.cloudflare.com/client/v4/accounts/{self.account_id}/storage/kv/namespaces/{namespace_id}/values/{key}"
        headers = {"Authorization": f"Bearer {self.api_token}"}
        try:
            response = requests.get(url, headers=headers)
            if response.status_code == 200:
                return {"success": True, "value": response.text}
            return {"success": False, "error": "Not Found"}
        except Exception as e:
            return {"success": False, "error": str(e)}

class CRCManip:
    def __init__(self, crcmanip_executable="./other/crcmanip"):
        self.crcmanip_path = crcmanip_executable
        self.ensure_executable()
    
    def ensure_executable(self):
        if os.path.exists(self.crcmanip_path):
            if not os.access(self.crcmanip_path, os.X_OK):
                os.chmod(self.crcmanip_path, os.stat(self.crcmanip_path).st_mode | stat.S_IEXEC)
   
    def get_file_size(self, file_path):
        return os.path.getsize(file_path)

    def get_crc(self, input_path, crc_type="CRC32"):
        args = ["calc", str(input_path), "-a", crc_type]
        return self.execute_command(args)

    def execute_command(self, args):
        command = [self.crcmanip_path] + args
        result = subprocess.run(command, capture_output=True, text=True, check=True)
        return result.stdout
    
    def adjust_file_size(self, file_path, target_size_bytes, position=None):
        current_size = self.get_file_size(file_path)
        
        if current_size == target_size_bytes:
            return True

        with open(file_path, 'rb') as f:
            content = f.read()

        if current_size < target_size_bytes:
            padding_size = target_size_bytes - current_size
            padding = b'\x00' * padding_size
            
            if position is None:
                insert_pos = len(content)
            elif position >= 0:
                insert_pos = min(position, len(content))
            else:
                insert_pos = max(len(content) + position, 0)
            
            new_content = content[:insert_pos] + padding + content[insert_pos:]
        else:
            new_content = content
            print("文件过大，处理失败。")
        with open(file_path, 'wb') as f:
            f.write(new_content)
        return True

    def insert(self, input_path, output_path, crc32_value, position, target_size_bytes=None, adjust_position=None):
        if target_size_bytes is not None:
            base_size = max(0, target_size_bytes - 4)
            self.adjust_file_size(input_path, base_size, adjust_position)
            
        args = ["patch", str(input_path), str(output_path), crc32_value, "-p", str(position)]
        return self.execute_command(args)
    
    def normal_execute(self, input_path, output_path, crc32_value, target_size_bytes=None, adjust_position=None):
        if target_size_bytes is not None:
            base_size = max(0, target_size_bytes - 4)
            self.adjust_file_size(input_path, base_size, adjust_position)
            
        args = ["p", str(input_path), str(output_path), crc32_value]
        return self.execute_command(args)
